What you should say (talk track)

â€œToday, placing an order still means filling out rigid fields.
Traders think in intent â€” not fields.â€

â€œOur goal is to build an AI-powered trading GUI where the user can simply say:
Buy 100k AAPL with minimal impact.â€

â€œThe GUI converts that intent into a fully structured order â€” instrument, side, quantity, urgency, constraints â€” and explains what it understood.â€

â€œNothing is auto-executed blindly.
The user always sees, understands, and controls the outcome.â€

Key message to land:
ğŸ‘‰ This is an intent-capture and decision-support system â€” not auto-trading.


What you should say

â€œOnce intent is understood, the next step is strategy â€” not execution.â€

â€œIn phase one, we intentionally limit scope to VWAP, TWAP, and POV.
These are well-understood, benchmarkable, and safe for learning.â€

â€œThe AI doesnâ€™t just suggest a strategy â€” it explains why:
liquidity, order size, urgency, and the userâ€™s past behavior.â€

â€œIf the user modifies or overrides the suggestion, that decision is not treated as an error â€” itâ€™s treated as a learning signal.â€

â€œThis is how we personalize without losing control.â€

Key message to land:
ğŸ‘‰ We optimize for alignment with trader expectations, not blind optimization.

What you should say

â€œThis is the most important slide â€” and also the most misunderstood topic: learning.â€

â€œThere is no real-time learning in production.
Nothing adapts while an order is being executed.â€

â€œAll learning happens offline, typically end-of-day.â€

â€œAgent captures explicit user corrections â€” accepts, overrides, parameter changes.â€

â€œAPO reinforcement learning is used to improve prompts, reasoning, and strategy mapping â€” not to change execution behavior directly.â€

â€œEvery change goes through human review, approval, and rollback.â€

â€œThis ensures we improve safely, audibly, and incrementally.â€

Key message to land:
ğŸ‘‰ Inference is real-time. Learning is offline. Humans stay in control.
